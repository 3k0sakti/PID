{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f98159e",
   "metadata": {},
   "source": [
    "# Advanced Sensor Data Analysis\n",
    "\n",
    "## Deskripsi\n",
    "Notebook ini berisi analisis lanjutan untuk data sensor yang sudah diproses melalui ETL pipeline. Anda akan belajar:\n",
    "\n",
    "- 📊 **Visualisasi Advanced**: Time series plots, correlation analysis, distribution analysis\n",
    "- 🔍 **Anomaly Detection**: Identifikasi outliers dan nilai abnormal\n",
    "- 📈 **Trend Analysis**: Pattern recognition dan seasonal analysis  \n",
    "- 🎯 **Performance Monitoring**: Sensor health dan maintenance prediction\n",
    "- 📋 **Reporting**: Automated report generation\n",
    "\n",
    "## Prerequisites\n",
    "Pastikan Anda sudah menjalankan:\n",
    "1. ETL Pipeline (`01_ETL_Sensor_Data_Tutorial.ipynb`)\n",
    "2. Data sudah tersedia di folder `data/output/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010de1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom utilities\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.sensor_utils import *\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"📊 Ready for advanced sensor data analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb3bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Find the latest processed data file\n",
    "output_files = glob.glob('data/output/processed_sensor_data_*.csv')\n",
    "\n",
    "if output_files:\n",
    "    # Get the most recent file\n",
    "    latest_file = max(output_files, key=os.path.getctime)\n",
    "    df = pd.read_csv(latest_file)\n",
    "    \n",
    "    # Convert timestamp if present\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    print(f\"✅ Loaded data from: {latest_file}\")\n",
    "    print(f\"📊 Dataset shape: {df.shape}\")\n",
    "    print(f\"📅 Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\" if 'timestamp' in df.columns else \"\")\n",
    "    print(\"\\\\nFirst few rows:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"❌ No processed data found!\")\n",
    "    print(\"Please run the ETL pipeline first: 01_ETL_Sensor_Data_Tutorial.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
